{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damaris-20/D_Web-Posts/blob/main/dama1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1q  from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmXpWQdGKHyY",
        "outputId": "7d52d87f-4b47-400f-9ef8-71925e59f391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db2-v_cLLJ--",
        "outputId": "d271a1b4-f5dc-4a6d-b3cd-daba86e5a94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'AI  pytorch.ipynb'\n",
            "'Ai tensorflow.ipynb'\n",
            "'big data2.ipynb'\n",
            " bigdata.ipynb\n",
            "'Big Data.ipynb'\n",
            "'Building the GRU.ipynb'\n",
            " chest_xray\n",
            "'Copy of machinelearning project.ipynb'\n",
            "'Copy of Reliance_stock_prediction.ipynb'\n",
            "'Copy of transformer.ipynb'\n",
            "'Copy of Trial2 (1).ipynb'\n",
            "'Copy of Untitled9.ipynb'\n",
            " cybersecurity_intrusion_data.csv\n",
            " dama1.ipynb\n",
            " Damah_merged_weather_data.xlsx\n",
            " damaris.ipynb\n",
            " data.csv\n",
            " dataset_datascience.csv\n",
            "'deep learning.ipynb'\n",
            "'EAST AFRICA COUNTRIES shapefiles.zip'\n",
            "'fine tuning 1.ipynb'\n",
            " gadm_level_0\n",
            "'HIV data 2000-2023.csv'\n",
            "'Hotel Reservations.csv'\n",
            " Housing1.csv\n",
            "'LSTM code.ipynb'\n",
            "'machinelearning project.ipynb'\n",
            "'ML with big data.ipynb'\n",
            " MobileNetSSD_deploy.caffemodel\n",
            " MobileNetSSD_deploy.prototxt\n",
            "'model pred2.ipynb'\n",
            " multidimensional_poverty.xlsx\n",
            " neonatal_mortality_rate.csv\n",
            "'pnuemonia diagnosis.ipynb'\n",
            " predicting.ipynb\n",
            "'project visualization and cleaning.ipynb'\n",
            "'prophet  booking status.ipynb'\n",
            "'prophet for both status.ipynb'\n",
            " question1_part1.ipynb\n",
            " question1_part2.ipynb\n",
            " question2.ipynb\n",
            " ResNet.ipynb\n",
            "'revenue projection.ipynb'\n",
            " roomallocation2.ipynb\n",
            " roomallocations.ipynb\n",
            "'seismic bumps dataset.ipynb'\n",
            "'SimpleAnn with AI.ipynb'\n",
            " style.css\n",
            " Taxi_Trip_Data.csv\n",
            " test.csv\n",
            "'time series hotel booking.ipynb'\n",
            "'transfer_learning (1).ipynb'\n",
            " transfer_learning.ipynb\n",
            "'Trial2 (1).ipynb'\n",
            "'under_five mortality rate.csv'\n",
            " Untitled0.ipynb\n",
            " Untitled10.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            " Untitled4.ipynb\n",
            " Untitled5.ipynb\n",
            " Untitled6.ipynb\n",
            " Untitled8.ipynb\n",
            " Updated_machinelearning_project.ipynb\n",
            " VAB2.ipynb\n",
            " vab3.ipynb\n",
            " vab4.ipynb\n",
            " VAB.ipynb\n",
            " vabtrial.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/Colab Notebooks/Damah_merged_weather_data.xlsx\""
      ],
      "metadata": {
        "id": "loyc0VX3LVdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYbQGfHKJtmI",
        "outputId": "24f73bc5-a59c-46d0-9b2f-362b993ee199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        rain       1.00      1.00      1.00       799\n",
            "   rain,snow       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00       800\n",
            "   macro avg       0.50      0.50      0.50       800\n",
            "weighted avg       1.00      1.00      1.00       800\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load Data\n",
        "df = pd.read_excel(path)\n",
        "\n",
        "# Drop rows with missing values in key columns\n",
        "df = df[['temp', 'humidity', 'precip', 'windspeed', 'cloudcover', 'preciptype']].dropna()\n",
        "\n",
        "# Features and Target\n",
        "X = df[['temp', 'humidity', 'precip', 'windspeed']]\n",
        "y = df['preciptype']\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
        "\n",
        "# Initialize and Train XGBoost Classifier\n",
        "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(le.classes_), eval_metric='mlogloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Decode the predictions back to original labels for the classification report\n",
        "y_pred_decoded = le.inverse_transform(y_pred)\n",
        "y_test_decoded = le.inverse_transform(y_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test_decoded, y_pred_decoded)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_decoded, y_pred_decoded))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCO2y0KdXeDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (R²): {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak_1IS5gXQqT",
        "outputId": "46d80e7c-b638-44d0-e81d-b2d0a6876a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.0013\n",
            "R-squared (R²): -0.0013\n"
          ]
        }
      ]
    }
  ]
}